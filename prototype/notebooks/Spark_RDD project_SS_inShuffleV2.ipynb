{"cells":[{"cell_type":"markdown","source":["#### Project CCF pySpark RDD"],"metadata":{}},{"cell_type":"code","source":["r=sc.parallelize([(\"A\",\"B\"),(\"B\",\"C\"),(\"B\",\"D\"),(\"D\",\"E\"),(\"F\",\"G\"),(\"G\",\"H\"),(\"A\",\"H\"),(\"G\",\"H\"),(\"I\",\"H\"),(\"L\",\"H\"),(\"M\",\"H\"),(\"Z\",\"J\")],2)\nr.collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[103]: [(&#39;A&#39;, &#39;B&#39;),\n (&#39;B&#39;, &#39;C&#39;),\n (&#39;B&#39;, &#39;D&#39;),\n (&#39;D&#39;, &#39;E&#39;),\n (&#39;F&#39;, &#39;G&#39;),\n (&#39;G&#39;, &#39;H&#39;),\n (&#39;A&#39;, &#39;H&#39;),\n (&#39;G&#39;, &#39;H&#39;),\n (&#39;I&#39;, &#39;H&#39;),\n (&#39;L&#39;, &#39;H&#39;),\n (&#39;M&#39;, &#39;H&#39;),\n (&#39;Z&#39;, &#39;J&#39;)]</div>"]}}],"execution_count":2},{"cell_type":"code","source":["from itertools import islice\ng=sc.textFile(\"FileStore/tables/webGoogleS.txt\")\n#remove header 4 lines\ndata= g.mapPartitionsWithIndex(lambda idx, it: islice(it, 4, None) if idx == 0 else it)\ndata.count()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[83]: 41306</div>"]}}],"execution_count":3},{"cell_type":"code","source":["p = data.map(lambda x: x.split(\"\\t\")).map(lambda x: (x[0], x[1]))\np.take(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[88]: [(&#39;0&#39;, &#39;11342&#39;),\n (&#39;0&#39;, &#39;824020&#39;),\n (&#39;0&#39;, &#39;867923&#39;),\n (&#39;0&#39;, &#39;891835&#39;),\n (&#39;11342&#39;, &#39;0&#39;)]</div>"]}}],"execution_count":4},{"cell_type":"code","source":["def CCF_Iterate_reduce(pair):\n  key, values = pair[0],list(pair[1])\n  #global accum\n  min = key\n  valueL = []\n  for value in values:\n    if value < min:\n       min = value\n    valueL.append(value)\n  if min < key:\n    yield((key, min))\n    for value in valueL:\n      if min != value:\n        accum.add(1)\n        yield((value, min))"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["log4jLogger = sc._jvm.org.apache.log4j\nLOGGER = log4jLogger.LogManager.getLogger(__name__)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["\nnew_pair_flag = True\niteration = 0\naccum = sc.accumulator(0)\ndedupJob = r"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["#for secondary sort\n\nfrom pyspark.rdd import portable_hash\nimport itertools\n\nn = 2 # number to hash\ndef partitioner(n):\n   # Partition by the first item in the key tuple\n    def partitioner_(x):\n        return portable_hash(x[0]) % n\n    return partitioner_\n\n\ndef unpair2(entry):\n    return entry[0][0], entry[0][1]\n  \ndef sorted_group(lines):\n    return itertools.groupby(lines, key=lambda x: x[0])\n  \ndef CCF_Iterate_reduce_SS_shuffle_test(pair):\n  key, values = pair\n  minvaluepair = next(values)\n  minvalue=minvaluepair[1]\n  \n  if minvalue < key:\n    #return key, minvalue\n    yield key, minvalue\n    for value in values:\n     # if minvalue != value[1]:\n      accum.add(1)\n      yield value[1], minvalue\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["while new_pair_flag:\n    iteration += 1\n    newPair = False\n    accum.value = 0\n\n    # CCF-iterate (MAP)\n    mapJob = dedupJob.flatMap(lambda e: (e,e[::-1]))\n    #print(mapJob.collect())\n    \n    #Secondary Sort\n    rddSS= (mapJob\n      .keyBy(lambda kv: (kv[0], kv[1][0]))  # Create temporary composite key\n      .repartitionAndSortWithinPartitions(numPartitions=n, partitionFunc=partitioner(n), ascending=True))\n  #.map(lambda x: x[1]))  # Drop key (note: there is no partitioner set anymore)\n    #for Secondary sort\n    unpairedRDD = rddSS.map(unpair2, preservesPartitioning=True)\n    groupedRDD = unpairedRDD.mapPartitions(sorted_group, preservesPartitioning=True)\n    reduceJob = groupedRDD.flatMap(CCF_Iterate_reduce_SS_shuffle_test)\n    # CCF-iterate (REDUCE)\n   # reduceJob = rddSS.groupByKey().flatMap(lambda pair: CCF_Iterate_reduce_SS_shuffle(pair))#.sortByKey()\n   # reduceJob = rddSS.groupByKey().flatMap(lambda pair: CCF_Iterate_reduce(pair))#.sortByKey()\n    \n  # CCF-dedup \n    dedupJob = reduceJob.distinct()\n\n    # Force the RDD evalusation\n    tmp = dedupJob.count()\n    #print(dedupJob.collect())\n    # Prepare next iteration\n    #mapJob = dedupJob\n    new_pair_flag = bool(accum.value)\n\n    #LOGGER.warn(\"Iteration :\"+str(iteration)+\" --- \"+\" newPair : \"+str(new_pair_flag))\n    print(\"Iteration :\"+str(iteration)+\" --- \"+\" newPair : \"+str(new_pair_flag) + str(accum.value))\n    #for analyse\n    results = list(dedupJob.map(lambda e: e[::-1]).groupByKey().map(lambda x : (x[0],tuple(x[1]))).collect())\nfor k in results:\n    print(\"Component id: \"+str(k[0])+\"| Number of nodes= \"+str(len(k[1])+1))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Iteration :1 ---  newPair : True10\nIteration :2 ---  newPair : True15\nIteration :3 ---  newPair : True4\nIteration :4 ---  newPair : False0\nComponent id: J| Number of nodes= 2\nComponent id: A| Number of nodes= 11\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":["r=sc.parallelize([(\"A\",\"B\"),(\"B\",\"C\"),(\"B\",\"D\"),(\"D\",\"E\"),(\"F\",\"G\"),(\"G\",\"H\"),(\"A\",\"H\"),(\"G\",\"H\"),(\"I\",\"H\")],2)\nmapJob = r.flatMap(lambda e: (e,e[::-1]))\n    #print(mapJob.collect())\n    \n    #Secondary Sort\nn=3\nrddSS= (mapJob\n  .keyBy(lambda kv: (kv[0], kv[1][0]))  # Create temporary composite key\n  .repartitionAndSortWithinPartitions(numPartitions=n, partitionFunc=partitioner(n), ascending=True))\n  #.map(lambda x: x[1]))  # Drop key (note: there is no partitioner set anymore)\nrddSS.glom().collect()\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[92]: [[((&#39;B&#39;, &#39;A&#39;), (&#39;B&#39;, &#39;A&#39;)),\n  ((&#39;B&#39;, &#39;C&#39;), (&#39;B&#39;, &#39;C&#39;)),\n  ((&#39;B&#39;, &#39;D&#39;), (&#39;B&#39;, &#39;D&#39;)),\n  ((&#39;C&#39;, &#39;B&#39;), (&#39;C&#39;, &#39;B&#39;)),\n  ((&#39;D&#39;, &#39;B&#39;), (&#39;D&#39;, &#39;B&#39;)),\n  ((&#39;D&#39;, &#39;E&#39;), (&#39;D&#39;, &#39;E&#39;))],\n [((&#39;A&#39;, &#39;B&#39;), (&#39;A&#39;, &#39;B&#39;)),\n  ((&#39;A&#39;, &#39;H&#39;), (&#39;A&#39;, &#39;H&#39;)),\n  ((&#39;G&#39;, &#39;F&#39;), (&#39;G&#39;, &#39;F&#39;)),\n  ((&#39;G&#39;, &#39;H&#39;), (&#39;G&#39;, &#39;H&#39;)),\n  ((&#39;G&#39;, &#39;H&#39;), (&#39;G&#39;, &#39;H&#39;)),\n  ((&#39;H&#39;, &#39;A&#39;), (&#39;H&#39;, &#39;A&#39;)),\n  ((&#39;H&#39;, &#39;G&#39;), (&#39;H&#39;, &#39;G&#39;)),\n  ((&#39;H&#39;, &#39;G&#39;), (&#39;H&#39;, &#39;G&#39;)),\n  ((&#39;H&#39;, &#39;I&#39;), (&#39;H&#39;, &#39;I&#39;))],\n [((&#39;E&#39;, &#39;D&#39;), (&#39;E&#39;, &#39;D&#39;)),\n  ((&#39;F&#39;, &#39;G&#39;), (&#39;F&#39;, &#39;G&#39;)),\n  ((&#39;I&#39;, &#39;H&#39;), (&#39;I&#39;, &#39;H&#39;))]]</div>"]}}],"execution_count":10},{"cell_type":"code","source":["def unpair2(entry):\n    return entry[0][0], entry[0][1]\n  \ndef sorted_group(lines):\n    return itertools.groupby(lines, key=lambda x: x[0])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"code","source":["unpairedRDD = rddSS.map(unpair2, preservesPartitioning=True)\n\nunpairedRDD.glom().collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[96]: [[(&#39;B&#39;, &#39;A&#39;), (&#39;B&#39;, &#39;C&#39;), (&#39;B&#39;, &#39;D&#39;), (&#39;C&#39;, &#39;B&#39;), (&#39;D&#39;, &#39;B&#39;), (&#39;D&#39;, &#39;E&#39;)],\n [(&#39;A&#39;, &#39;B&#39;),\n  (&#39;A&#39;, &#39;H&#39;),\n  (&#39;G&#39;, &#39;F&#39;),\n  (&#39;G&#39;, &#39;H&#39;),\n  (&#39;G&#39;, &#39;H&#39;),\n  (&#39;H&#39;, &#39;A&#39;),\n  (&#39;H&#39;, &#39;G&#39;),\n  (&#39;H&#39;, &#39;G&#39;),\n  (&#39;H&#39;, &#39;I&#39;)],\n [(&#39;E&#39;, &#39;D&#39;), (&#39;F&#39;, &#39;G&#39;), (&#39;I&#39;, &#39;H&#39;)]]</div>"]}}],"execution_count":12},{"cell_type":"code","source":["groupedRDD = unpairedRDD.mapPartitions(sorted_group, preservesPartitioning=True)\ngroupedRDD.glom().collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[97]: [[(&#39;B&#39;, &lt;tuple_iterator at 0x7f42b15837b8&gt;),\n  (&#39;C&#39;, &lt;tuple_iterator at 0x7f42b15b7940&gt;),\n  (&#39;D&#39;, &lt;tuple_iterator at 0x7f42b15b7ef0&gt;)],\n [(&#39;A&#39;, &lt;tuple_iterator at 0x7f42b15b7dd8&gt;),\n  (&#39;G&#39;, &lt;tuple_iterator at 0x7f42b135a470&gt;),\n  (&#39;H&#39;, &lt;tuple_iterator at 0x7f42b135a550&gt;)],\n [(&#39;E&#39;, &lt;tuple_iterator at 0x7f42b15b7b00&gt;),\n  (&#39;F&#39;, &lt;tuple_iterator at 0x7f42b135aba8&gt;),\n  (&#39;I&#39;, &lt;tuple_iterator at 0x7f42b135a2e8&gt;)]]</div>"]}}],"execution_count":13},{"cell_type":"code","source":["    # CCF-iterate (REDUCE)\naccum = sc.accumulator(0)\nreduceJob = groupedRDD.flatMap(CCF_Iterate_reduce_SS_shuffle_test)\nreduceJob.collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[98]: [(&#39;B&#39;, &#39;A&#39;),\n (&#39;C&#39;, &#39;A&#39;),\n (&#39;D&#39;, &#39;A&#39;),\n (&#39;C&#39;, &#39;B&#39;),\n (&#39;D&#39;, &#39;B&#39;),\n (&#39;E&#39;, &#39;B&#39;),\n (&#39;G&#39;, &#39;F&#39;),\n (&#39;H&#39;, &#39;F&#39;),\n (&#39;H&#39;, &#39;F&#39;),\n (&#39;H&#39;, &#39;A&#39;),\n (&#39;G&#39;, &#39;A&#39;),\n (&#39;G&#39;, &#39;A&#39;),\n (&#39;I&#39;, &#39;A&#39;),\n (&#39;E&#39;, &#39;D&#39;),\n (&#39;I&#39;, &#39;H&#39;)]</div>"]}}],"execution_count":14}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.7","nbconvert_exporter":"python","file_extension":".py"},"name":"Spark_RDD project","notebookId":121916573732034},"nbformat":4,"nbformat_minor":0}
