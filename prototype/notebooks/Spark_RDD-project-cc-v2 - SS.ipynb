{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession \n",
    "from pyspark import SparkConf,SparkContext\n",
    "import os\n",
    "\n",
    "conf = SparkConf()\n",
    "#conf.setMaster('local')\n",
    "#conf.setAppName('pyspark-shell')\n",
    "#conf.set('spark.driver.host', '127.0.0.1')\n",
    "#os.environ['PYSPARK_PYTHON'] = '/Users/ccompain/.pyenv/versions/miniconda3-latest/bin/python' # Needs to be explicitly provided as env. Otherwise workers run Python 2.7\n",
    "#os.environ['PYSPARK_DRIVER_PYTHON'] = 'jupyter'\n",
    "\n",
    "#sc = SparkContext(conf=conf)\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "\n",
    "sc.setLogLevel(\"WARN\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'B'), ('B', 'C'), ('B', 'D'), ('D', 'E'), ('F', 'G'), ('G', 'H')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r=sc.parallelize([(\"A\",\"B\"),(\"B\",\"C\"),(\"B\",\"D\"),(\"D\",\"E\"),(\"F\",\"G\"),(\"G\",\"H\")],2)\n",
    "r.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CCF_Iterate_reduce_SS(pair):\n",
    "  key, values = pair[0],list(pair[1])\n",
    "  global accum\n",
    "  values.sort()\n",
    "  min = values.pop(0)\n",
    "  if min < key:\n",
    "    yield((key, min))\n",
    "    for value in values:\n",
    "      accum.add(1)\n",
    "      yield((value, min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "log4jLogger = sc._jvm.org.apache.log4j\n",
    "LOGGER = log4jLogger.LogManager.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pair_flag = True\n",
    "iteration = 0\n",
    "accum = sc.accumulator(0)\n",
    "dedupJob = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration :1 ---  newPair : True\n",
      "Iteration :2 ---  newPair : True\n",
      "Iteration :3 ---  newPair : True\n",
      "Iteration :4 ---  newPair : False\n"
     ]
    }
   ],
   "source": [
    "while new_pair_flag:\n",
    "    iteration += 1\n",
    "    newPair = False\n",
    "    accum.value = 0\n",
    "\n",
    "    # CCF-iterate (MAP)\n",
    "    mapJob = dedupJob.flatMap(lambda e: (e,e[::-1]))\n",
    "    #print(mapJob.collect())\n",
    "\n",
    "    # CCF-iterate (REDUCE)\n",
    "    reduceJob = mapJob.groupByKey().flatMap(lambda pair: CCF_Iterate_reduce_SS(pair))#.sortByKey()\n",
    "\n",
    "    # CCF-dedup \n",
    "    dedupJob = reduceJob.distinct()\n",
    "\n",
    "    # Force the RDD evalusation\n",
    "    tmp = dedupJob.count()\n",
    "\n",
    "    # Prepare next iteration\n",
    "    #mapJob = dedupJob\n",
    "    new_pair_flag = bool(accum.value)\n",
    "\n",
    "    #LOGGER.warn(\"Iteration :\"+str(iteration)+\" --- \"+\" newPair : \"+str(new_pair_flag))\n",
    "    print(\"Iteration :\"+str(iteration)+\" --- \"+\" newPair : \"+str(new_pair_flag))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group id: A | Components: ['A', 'B', 'C', 'D', 'E'] | Number of nodes:  5\n",
      "Group id: F | Components: ['F', 'G', 'H'] | Number of nodes:  3\n"
     ]
    }
   ],
   "source": [
    "results = list(dedupJob.map(lambda e: e[::-1]).groupByKey().map(lambda x : (x[0],tuple(x[1]))).collect())\n",
    "#list(map(lambda e: e[::-1], mapJob.collect()))\n",
    "#print(results)\n",
    "for k in results:\n",
    "\n",
    "    print(\"Group id:\",k[0],\"| Components:\", sorted(list(x for elem in k for x in elem))  , \"| Number of nodes: \", len(k[1]) +1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
