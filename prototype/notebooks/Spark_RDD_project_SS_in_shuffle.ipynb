{"cells":[{"cell_type":"markdown","source":["#### Project CCF pySpark RDD"],"metadata":{}},{"cell_type":"code","source":["r=sc.parallelize([(\"A\",\"B\"),(\"B\",\"C\"),(\"B\",\"D\"),(\"D\",\"E\"),(\"F\",\"G\"),(\"G\",\"H\")],2)\nr.collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[143]: [(&#39;A&#39;, &#39;B&#39;), (&#39;B&#39;, &#39;C&#39;), (&#39;B&#39;, &#39;D&#39;), (&#39;D&#39;, &#39;E&#39;), (&#39;F&#39;, &#39;G&#39;), (&#39;G&#39;, &#39;H&#39;)]</div>"]}}],"execution_count":2},{"cell_type":"code","source":["def CCF_Iterate_reduce(pair):\n  key, values = pair[0],list(pair[1])\n  #global accum\n  min = key\n  valueL = []\n  for value in values:\n    if value < min:\n       min = value\n    valueL.append(value)\n  if min < key:\n    yield((key, min))\n    for value in valueL:\n      if min != value:\n        accum.add(1)\n        yield((value, min))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["log4jLogger = sc._jvm.org.apache.log4j\nLOGGER = log4jLogger.LogManager.getLogger(__name__)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["\nnew_pair_flag = True\niteration = 0\naccum = sc.accumulator(0)\ndedupJob = r"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["#for secondary sort\n\nfrom pyspark.rdd import portable_hash\n\nn = 3 # number to hash\ndef partitioner(n):\n   # Partition by the first item in the key tuple\n    def partitioner_(x):\n        return portable_hash(x[0]) % n\n    return partitioner_\n\n\ndef CCF_Iterate_reduce_SS_shuffle(pair):\n  key, values = pair[0],list(pair[1])\n  min = values.pop(0)\n  if min < key:\n    yield((key, min))\n    for value in values:\n      accum.add(1)\n      yield((value, min))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["while new_pair_flag:\n    iteration += 1\n    newPair = False\n    accum.value = 0\n\n    # CCF-iterate (MAP)\n    mapJob = dedupJob.flatMap(lambda e: (e,e[::-1]))\n    #print(mapJob.collect())\n    \n    #Secondary Sort\n    rddSS= (mapJob\n  .keyBy(lambda kv: (kv[0], kv[1][0]))  # Create temporary composite key\n  .repartitionAndSortWithinPartitions(numPartitions=n, partitionFunc=partitioner(n), ascending=True)\n  .map(lambda x: x[1]))  # Drop key (note: there is no partitioner set anymore)\n    \n    # CCF-iterate (REDUCE)\n    reduceJob = rddSS.groupByKey().flatMap(lambda pair: CCF_Iterate_reduce_SS_shuffle(pair))#.sortByKey()\n\n    # CCF-dedup \n    dedupJob = reduceJob.distinct()\n\n    # Force the RDD evalusation\n    tmp = dedupJob.count()\n    #print(dedupJob.collect())\n    # Prepare next iteration\n    #mapJob = dedupJob\n    new_pair_flag = bool(accum.value)\n\n    #LOGGER.warn(\"Iteration :\"+str(iteration)+\" --- \"+\" newPair : \"+str(new_pair_flag))\n    print(\"Iteration :\"+str(iteration)+\" --- \"+\" newPair : \"+str(new_pair_flag) + str(accum.value))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[(&#39;B&#39;, &#39;A&#39;), (&#39;C&#39;, &#39;A&#39;), (&#39;D&#39;, &#39;A&#39;), (&#39;C&#39;, &#39;B&#39;), (&#39;H&#39;, &#39;F&#39;), (&#39;H&#39;, &#39;G&#39;), (&#39;E&#39;, &#39;D&#39;), (&#39;E&#39;, &#39;B&#39;), (&#39;D&#39;, &#39;B&#39;), (&#39;G&#39;, &#39;F&#39;)]\nIteration :1 ---  newPair : True4\n[(&#39;B&#39;, &#39;A&#39;), (&#39;C&#39;, &#39;A&#39;), (&#39;D&#39;, &#39;A&#39;), (&#39;E&#39;, &#39;A&#39;), (&#39;H&#39;, &#39;F&#39;), (&#39;E&#39;, &#39;B&#39;), (&#39;G&#39;, &#39;F&#39;), (&#39;D&#39;, &#39;B&#39;)]\nIteration :2 ---  newPair : True9\n[(&#39;B&#39;, &#39;A&#39;), (&#39;D&#39;, &#39;A&#39;), (&#39;E&#39;, &#39;A&#39;), (&#39;C&#39;, &#39;A&#39;), (&#39;H&#39;, &#39;F&#39;), (&#39;G&#39;, &#39;F&#39;)]\nIteration :3 ---  newPair : True4\n[(&#39;B&#39;, &#39;A&#39;), (&#39;C&#39;, &#39;A&#39;), (&#39;D&#39;, &#39;A&#39;), (&#39;H&#39;, &#39;F&#39;), (&#39;E&#39;, &#39;A&#39;), (&#39;G&#39;, &#39;F&#39;)]\nIteration :4 ---  newPair : False0\n</div>"]}}],"execution_count":7}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.7","nbconvert_exporter":"python","file_extension":".py"},"name":"Spark_RDD project","notebookId":651826418773713},"nbformat":4,"nbformat_minor":0}
